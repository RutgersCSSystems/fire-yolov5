fclose PID:8490 fd:3
fclose PID:8490 fd:4
fclose PID:8490 fd:4
fclose PID:8490 fd:3
available: 2 nodes (0-1)
fclose PID:8490 fd:4
node 0 cpus:fclose PID:8490 fd:4
 0 1 2 3 4 5 6 7 16 17 18 19 20 21 22 23
node 0 size: 64178 MB
node 0 free: 63892 MB
fclose PID:8490 fd:4
node 1 cpus:fclose PID:8490 fd:4
 8 9 10 11 12 13 14 15 24 25 26 27 28 29 30 31
node 1 size: 64487 MB
node 1 free: 64301 MB
fclose PID:8490 fd:4
fclose PID:8490 fd:4
node distances:
node   0   1 
  0:  10  21 
  1:  21  10 
READAHEAD_TIME:0.000000 us
MaxRSS= 3964 KB, SharedMem= 0 KB, HardPageFault= 9
fclose PID:8498 fd:15
fclose PID:8501 fd:12
fclose PID:8503 fd:12
fclose PID:8504 fd:12
fclose PID:8499 fd:14
fclose PID:8500 fd:12
fclose PID:8502 fd:12
fclose PID:8505 fd:12
IOR-3.4.0+dev: MPI Coordinated Test of Parallel I/O
Began               : Tue Mar 16 14:53:45 2021
Command line        : ior -e -o test_outfile_ior -v -b 1048576000 -t 1048576 -s 256 -C -F -k
Machine             : Linux c220g1.sudarsun4.fsperfatscale-pg0.wisc.cloudlab.us
Start time skew across all tasks: 0.00 sec
TestID              : 0
StartTime           : Tue Mar 16 14:53:45 2021
Path                : test_outfile_ior.00000000
FS                  : 439.1 GiB   Used FS: 73.6%   Inodes: 28.0 Mi   Used Inodes: 0.6%
Participating tasks : 8
Using reorderTasks '-C' (useful to avoid read cache in client)

Options: 
api                 : POSIX
apiVersion          : 
test filename       : test_outfile_ior
access              : file-per-process
type                : independent
segments            : 256
ordering in a file  : sequential
ordering inter file : constant task offset
task offset         : 1
nodes               : 1
tasks               : 8
clients per node    : 8
repetitions         : 1
xfersize            : 1 MiB
blocksize           : 1000 MiB
aggregate filesize  : 1.95 TiB
verbose             : 1

Results: 

access    bw(MiB/s)  IOPS       Latency(s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ----       ----------  ---------- ---------  --------   --------   --------   --------   ----
Commencing write performance test: Tue Mar 16 14:53:45 2021
WARNING: Task 2, partial write(), 516096 of 1048576 bytes at offset 39315308544
ERROR: write(12, 0x7f4bfc3a0000, 532480) failed, (aiori-POSIX.c:563)
WARNING: Task 5, partial write(), 135168 of 1048576 bytes at offset 39299579904
ERROR: write(12, 0x7f1d032c4000, 913408) failed, (aiori-POSIX.c:563)
WARNING: Task 7, partial write(), 102400 of 1048576 bytes at offset 39331037184
ERROR: write(12, 0x7fb0890f2000, 946176) failed, (aiori-POSIX.c:563)
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 5
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 7
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 2
WARNING: Task 1, partial write(), 716800 of 1048576 bytes at offset 39448477696
ERROR: write(14, 0x7fc11a1ed000, 331776) failed, (aiori-POSIX.c:563)
WARNING: Task 4, partial write(), 1032192 of 1048576 bytes at offset 39311114240
ERROR: write(12, 0x7f80edd16000, 16384) failed, (aiori-POSIX.c:563)
WARNING: Task 6, partial write(), 868352 of 1048576 bytes at offset 39364591616
ERROR: write(12, 0x7f68efe95000, 180224) failed, (aiori-POSIX.c:563)
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 1
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 4
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 6
WARNING: Task 0, partial write(), 1040384 of 1048576 bytes at offset 39325794304
ERROR: write(15, 0x7fedcce3f000, 8192) failed, (aiori-POSIX.c:563)
WARNING: Task 3, partial write(), 126976 of 1048576 bytes at offset 39324745728
ERROR: write(12, 0x7f5e4317a000, 921600) failed, (aiori-POSIX.c:563)
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 0
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 3
fclose PID:8496 fd:4
fclose PID:8496 fd:5
fclose PID:8496 fd:5
fclose PID:8496 fd:4
READAHEAD_TIME:0.000000 us
MaxRSS= 8588 KB, SharedMem= 0 KB, HardPageFault= 4
Command exited with non-zero status 255
	Command being timed: "mpirun -np 8 ior -e -o te