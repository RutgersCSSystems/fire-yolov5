fclose PID:7620 fd:3
fclose PID:7620 fd:4
fclose PID:7620 fd:4
fclose PID:7620 fd:3
available: 2 nodes (0-1)
fclose PID:7620 fd:3
node 0 cpus:fclose PID:7620 fd:3
 0 1 2 3 4 5 6 7 8 9 20 21 22 23 24 25 26 27 28 29
node 0 size: 80440 MB
node 0 free: 80117 MB
fclose PID:7620 fd:3
node 1 cpus:fclose PID:7620 fd:3
 10 11 12 13 14 15 16 17 18 19 30 31 32 33 34 35 36 37 38 39
node 1 size: 80635 MB
node 1 free: 80357 MB
fclose PID:7620 fd:3
fclose PID:7620 fd:3
node distances:
node   0   1 
  0:  10  21 
  1:  21  10 
READAHEAD_TIME:0.000000 us
MaxRSS= 2196 KB, SharedMem= 0 KB, HardPageFault= 10
fclose PID:7625 fd:12
IOR-3.4.0+dev: MPI Coordinated Test of Parallel I/O
Began               : Thu Mar 11 18:36:26 2021
Command line        : ior -r -o test_outfile_ior -v -b 209715200000 -t 1048576 -s 1
Machine             : Linux node-0.tester2.lsm-pg0.wisc.cloudlab.us
Start time skew across all tasks: 0.00 sec
TestID              : 0
StartTime           : Thu Mar 11 18:36:26 2021
Path                : test_outfile_ior
FS                  : 439.1 GiB   Used FS: 44.9%   Inodes: 28.0 Mi   Used Inodes: 0.3%
Participating tasks : 1

Options: 
api                 : POSIX
apiVersion          : 
test filename       : test_outfile_ior
access              : single-shared-file
type                : independent
segments            : 1
ordering in a file  : sequential
ordering inter file : no tasks offsets
nodes               : 1
tasks               : 1
clients per node    : 1
repetitions         : 1
xfersize            : 1 MiB
blocksize           : 195.31 GiB
aggregate filesize  : 195.31 GiB
verbose             : 1

Results: 

access    bw(MiB/s)  IOPS       Latency(s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ----       ----------  ---------- ---------  --------   --------   --------   --------   ----
Commencing read performance test: Thu Mar 11 18:36:26 2021

fclose PID:7623 fd:3
fclose PID:7623 fd:4
fclose PID:7623 fd:4
fclose PID:7623 fd:3
[mpiexec@node-0.tester2.lsm-pg0.wisc.cloudlab.us] Sending Ctrl-C to processes as requested
[mpiexec@node-0.tester2.lsm-pg0.wisc.cloudlab.us] Press Ctrl-C again to force abort
fclose PID:7624 fd:0
fclose PID:7624 fd:6
fclose PID:7624 fd:6
fclose PID:7624 fd:0
READAHEAD_TIME:0.000000 us
MaxRSS= 5316 KB, SharedMem= 0 KB, HardPageFault= 2
READAHEAD_TIME:0.000000 us
MaxRSS= 4920 KB, SharedMem= 0 KB, HardPageFault= 4
	Command being timed: "mpirun -np 1 ior -r -o test_outfile_ior -v -b 209715200000 -t 1048576 -s 1"
	User time (seconds): 3.93
	System time (seconds): 74.17
	Percent of CPU this job got: 18%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 7:10.26
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 12952
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 24
	Minor (reclaiming a frame) page faults: 3863
	Voluntary context switches: 180029
	Involuntary context switches: 581
	Swaps: 0
	File system inputs: 368301632
	File system outputs: 16
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
READAHEAD_TIME:0.000000 us
MaxRSS= 3912 KB, SharedMem= 0 KB, HardPageFault= 0
*******************DMESG OUTPUT******************
